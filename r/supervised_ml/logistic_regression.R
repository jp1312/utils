## --- Logistic regression


# Libraries
install.packages("caret")
library(caret)
install.packages("e1071")
library(e1071)
install.packages("ggthemes")
suppressMessages(library(ggthemes))


# Simulate data
set.seed(123)
x1 = rnorm(1000)           # some continuous variables 
x2 = rnorm(1000)
z = 1 + 2*x1 + 3*x2        # linear combination with a bias
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = rbinom(1000,1,pr)      # bernoulli response variable
df = data.frame(y=y,x1=x1,x2=x2)
  

# logistic regression
model_logit <- glm(y ~., data = df, family = binomial(logit))
summary(model_logit)

# Model parameters
system.time(odds_ratio <- exp(cbind(OR = coef(model_logit), confint(model_logit))))

# Quality of model

# 1. Difference in deviance
with(model_logit,model_logit$null.deviance - model_logit$deviance)
# 2. Difference of degrees of freedom
with(model_logit, df.null - df.residual)

# 3. p_value for global significance
pchisq(model_logit$null.deviance - model_logit$deviance, 
       model_logit$df.null - model_logit$df.residual, lower.tail = FALSE)

# Confusion Matrix
logit_data = df %>% mutate(
  predicted_prob = predict(model_logit,type = "response"),
  predicted_y = ifelse(predicted_prob>0.5,1,0))

with(logit_data, table(y,predicted_y))

head(logit_data)
str(logit_data)
# Quality of model
confusion_matrix = confusionMatrix(as.factor(logit_data$predicted_y),as.factor(logit_data$y))
confusion_matrix$table
round(confusion_matrix$overall,2)
confusion_matrix$byClass

# Roc curve
# Recall : ROC curves are graphic representations of the relation existing between the sensibility and the specificity of a test. It is generated by plotting the fraction of true positives out of the total actual positives versus the fraction of false positives out of the total actual negative

## Manually
myroc <- function(current_values, predicted_values){
  # Produces FPR and TPR co-ordinates for ROC curve plot
  # Arguments: cv - labels classifying subject status
  #            pv - probability values of each observation
  # Output: roc = data.frame with x and y co-ordinates of plot
  
  cv <- as.factor(current_values)
  pv= predicted_values
  if (length(pv) != length(cv)) {
    stop("The number of classifiers must match the number of data points")
  } 
  if (length(levels(cv)) != 2) {
    stop("There must only be 2 values for the classifier")
  }
  
  threshold <- seq(0,1,0.005)
  tp <- sapply(threshold, function(x) length(which(pv > x & cv == levels(cv)[2])))
  fn <- sapply(threshold, function(x) length(which(pv < x & cv == levels(cv)[2])))
  fp <- sapply(threshold, function(x) length(which(pv > x & cv == levels(cv)[1])))
  tn <- sapply(threshold, function(x) length(which(pv < x & cv == levels(cv)[1])))
  tpr <- tp / (tp + fn)
  fpr <- fp / (fp + tn)
  roc = data.frame(fpr = fpr, tpr = tpr)
  roc <- arrange(roc, fpr,tpr)
  return(roc)
}

roc_data = myroc(logit_data$y, logit_data$predicted_prob)
roc_data$color = cut(roc_data$fpr,breaks = seq(0,1,0.2))

# Plot
pl <- ggplot(roc_data, aes(x=fpr, y=tpr))
pl = pl + geom_line(aes(colour = color)) + scale_colour_gdocs() +theme_fivethirtyeight()
pl = pl+ geom_abline(intercept = 0, slope = 1,color = "grey10",size= 1.1)
pl + labs(title = "ROC Curve Manual", x ="False Positive Rate (1-Specificity)",
          y= "True Positive Rate (Sensitivity)")

# We can use package verification to compute the ROC curve

current_values = as.numeric(as.character(logit_data$y))
predicted_values= logit_data$predicted_prob
roc.plot(current_values, predicted_values,thresholds = seq(0,1,0.01))
# Area Under Curve
roc.area(current_values,predicted_values)
